{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to classify the data set of letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import PIL\n",
    "from persim import plot_diagrams\n",
    "from ripser import ripser, lower_star_img\n",
    "import csv\n",
    "import math\n",
    "import warnings\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# Function to return the betti numbers for dimensions 0 and 1, of the simplicial complex\n",
    "# created form a Rips filtration of a point cloud.\n",
    "def betti_nums(data, sType, scanStart, scanStop, eps = 100, showPlot = False, doSlice = False):\n",
    "    '''Inputs: -data: Your data set. Should be a list of 1's and 0's.\n",
    "    \n",
    "               -Stype: Scanning type. Should be a string either, 'ud'(up-and-down),\n",
    "                       'lr'(left-to-right), or 'rl'(right-to-left). \n",
    "                       *For down-and-up scanning, fix scanStop at the last index of \n",
    "                        your list, and alter scanStart.*\n",
    "                       **For slices, choose 'ud' for horizontal slices. Then choose scanStart \n",
    "                         and scanStop to match where you want to start and end your slice.**\n",
    "                       ***For middle-out scanning, repeat the slicing procedure, but\n",
    "                          increase scanStart and scanStop at the same time to gradually\n",
    "                          increment the size of the slice.***\n",
    "                       \n",
    "               -scanStart: Where to start scanning. For 'ud' and 'lr' scanning\n",
    "                           fix this to be the first index.\n",
    "                \n",
    "               -scanStop: Where to stop scanning. For 'du' scanning\n",
    "                          fix this to be the last index.\n",
    "                          \n",
    "               -eps: The max distance in a Rips filtration. This becomes our, \"infinity.\"\n",
    "                     This is initialized to 100. For more precision, decrease this to fit\n",
    "                     your data set.\n",
    "                     \n",
    "               -showPlot: Whether or not to show the PH diagrams. Initialized to False, change\n",
    "                          to True to show PH diagrams.\n",
    "                \n",
    "               -doSlice: Whether or not to so slice scanning. Initialized to False. Set to\n",
    "                         True if you wish to do slice scanning.\n",
    "        \n",
    "       Outputs: -(b0, b1): A tuple containing betti0 and betti1 for the scanning data set,\n",
    "                           depending on the scanning type and how much was scanned.\n",
    "    '''\n",
    "    \n",
    "    letter = np.array([[0,0]])    # Initializes an array of (1x2)-arrays.\n",
    "    \n",
    "    # Up-and-Down scanning.\n",
    "    if sType.lower() == 'ud':\n",
    "        \n",
    "        # Loops through the line with the letter data and if the kth position\n",
    "        # of the array is a 1, then the coordinates of that 1 is added as a\n",
    "        # 1x2 array to the letter array.\n",
    "        for k in range(scanStart,scanStop):\n",
    "            if data[k] == 1:\n",
    "                col = 10-int((k-1)/10)\n",
    "                row = (k-1)%10\n",
    "                letter = np.append(letter,[[row, col]], axis = 0)\n",
    "        \n",
    "        # Removes the first entry of letter, as it was a placeholder.\n",
    "        letter = np.delete(letter, 0, 0)\n",
    "        \n",
    "        # Test for the space (or just nothing), otherwise, the function breaks.\n",
    "        if len(letter) == 0:\n",
    "            return (0,0)\n",
    "        \n",
    "        # Filters the point cloud, using a Rips filtration up to a max dimension of 2.\n",
    "        diagrams = ripser(letter, maxdim = 1, metric = 'euclidean',thresh = eps)['dgms']\n",
    "        \n",
    "        # If the you want to see the shape of the data and the persistence diagram\n",
    "        # both are displayed.\n",
    "        if showPlot == True:\n",
    "            # Setting the x and y coordinates to be plotted to show the shape\n",
    "            # of the data.\n",
    "            x_data = [letter[i][0] for i in range(0,len(letter))]\n",
    "            y_data = [letter[i][1] for i in range(0,len(letter))]\n",
    "        \n",
    "            # Plots the shape of the data\n",
    "            plt.figure(1)\n",
    "            plt.plot(x_data, y_data, 'ro', scalex = True, scaley = True)\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([-1,11])\n",
    "            axes.set_ylim([-1,11])\n",
    "        \n",
    "            # Plots the PH diagram of the complex created from the Rips filtration\n",
    "            plt.figure(2)\n",
    "            plot_diagrams(diagrams, show=True, xy_range = [-0.25,5,-0.25,5])\n",
    "            \n",
    "    # Left-to-Right Scanning:\n",
    "    if sType.lower() == 'lr':\n",
    "        \n",
    "        # Tests if the the function is going to do left-to-right\n",
    "        # slice scanning or not. The scanning interval is changed\n",
    "        # accordingly.\n",
    "        if doSlice == False:\n",
    "            scanStart2 = 1\n",
    "            scanStop2 = 101\n",
    "        else:\n",
    "            scanStart2 = scanStart\n",
    "            scanStop2 = 101\n",
    "        \n",
    "        # Loops through the line with the letter data and if the kth position\n",
    "        # of the array is a 1, then the coordinates of that 1 is added as a\n",
    "        # 1x2 array to the letter array.\n",
    "        for k in range(scanStart2,scanStop2):\n",
    "            if data[k] == 1:\n",
    "                row = 10-int((k-1)/10)\n",
    "                col = (k-1)%10\n",
    "                letter = np.append(letter,[[row, col]], axis = 0)\n",
    "        \n",
    "        # Removes the first entry of letter, as it was a placeholder.\n",
    "        letter = np.delete(letter, 0, 0)\n",
    "        \n",
    "        # Test for the space (or just nothing), otherwise, the function breaks.\n",
    "        if len(letter) == 0:\n",
    "            return (0,0)\n",
    "        \n",
    "        # Rearranges the xy-coordinates to do left-to-right scanning.\n",
    "        y_data = np.array([letter[i][0] for i in range(0,len(letter)) for j in range(1,int(scanStop/10)) if letter[i][1] == j])\n",
    "        x_data = np.array([letter[i][1] for i in range(0,len(letter)) for j in range(1,int(scanStop/10)) if letter[i][1] == j])\n",
    "        \n",
    "        # Creates a new array with the the xy-coordinates oriented properly\n",
    "        # for left-to-right scanning.\n",
    "        letter2 = np.array([x_data,y_data])\n",
    "        letter2 = np.transpose(letter2)\n",
    "        \n",
    "        # Tests again to make sure there is something in the letter2 array.\n",
    "        # If there isn't, b0 = b1 = 0.\n",
    "        if len(letter2) == 0:\n",
    "            return (0,0)\n",
    "        \n",
    "        # Filters the point cloud, using a Rips filtration up to a max dimension of 2.\n",
    "        diagrams = ripser(letter2, maxdim = 1, metric = 'euclidean',thresh = eps)['dgms']\n",
    "        \n",
    "        # If the you want to see the shape of the data and the persistence diagram\n",
    "        # both are displayed.\n",
    "        if showPlot == True:\n",
    "            # Plots the shape of the data\n",
    "            plt.figure(1)\n",
    "            plt.plot(x_data, y_data, 'ro', scalex = True, scaley = True)\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([-1,11])\n",
    "            axes.set_ylim([-1,11])\n",
    "        \n",
    "            # Plots the PH diagram of the complex created from the Rips filtration\n",
    "            plt.figure(2)\n",
    "            plot_diagrams(diagrams, show=True, xy_range = [-0.25,5,-0.25,5])\n",
    "    \n",
    "    \n",
    "    # Right-to-Left Scanning:\n",
    "    if sType.lower() == 'rl':\n",
    "        \n",
    "        # Loops through the line with the letter data and if the kth position\n",
    "        # of the array is a 1, then the coordinates of that 1 is added as a\n",
    "        # 1x2 array to the letter array.\n",
    "        for k in range(1,101):\n",
    "            if data[k] == 1:\n",
    "                row = 10-int((k-1)/10)\n",
    "                col = 10-(k-1)%10\n",
    "                letter = np.append(letter,[[row, col]], axis = 0)\n",
    "    \n",
    "        # Removes the first entry of letter, as it was a placeholder.\n",
    "        letter = np.delete(letter, 0, 0)\n",
    "        \n",
    "        # Test for the space (or just nothing), otherwise, the function breaks.\n",
    "        if len(letter) == 0:\n",
    "            return (0,0)\n",
    "        \n",
    "        # Rearranges the xy-coordinates to do right-to-left scanning.\n",
    "        y_data = np.array([letter[i][0] for i in range(0,len(letter)) for j in range(1,int(scanStop/10)) if letter[i][1] == j])\n",
    "        x_data = np.array([letter[i][1] for i in range(0,len(letter)) for j in range(1,int(scanStop/10)) if letter[i][1] == j])\n",
    "        \n",
    "        # Creates a new array with the the xy-coordinates oriented properly\n",
    "        # for Right-to-Left scanning.\n",
    "        letter2 = np.array([x_data,y_data])\n",
    "        letter2 = np.transpose(letter2)\n",
    "        \n",
    "        # Tests again to make sure there is something in the letter2 array.\n",
    "        # If there isn't, b0 = b1 = 0.\n",
    "        if len(letter2) == 0:\n",
    "            return (0,0)\n",
    "        \n",
    "        # Filters the point cloud, using a Rips filtration up to a max dimension of 2.\n",
    "        diagrams = ripser(letter2, maxdim = 1, metric = 'euclidean',thresh = eps)['dgms']\n",
    "        \n",
    "        # If the you want to see the shape of the data and the persistence diagram\n",
    "        # both are displayed.\n",
    "        if showPlot == True:\n",
    "            # Plots the shape of the data\n",
    "            plt.figure(1)\n",
    "            plt.plot(x_data, y_data, 'ro', scalex = True, scaley = True)\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([-1,11])\n",
    "            axes.set_ylim([-1,11])\n",
    "        \n",
    "            # Plots the PH diagram of the complex created from the Rips filtration\n",
    "            plt.figure(2)\n",
    "            plot_diagrams(diagrams, show=True, xy_range = [-0.25,5,-0.25,5])\n",
    "        \n",
    "    # Calculates the 0-dim betti number.\n",
    "    betti0 = [1 for x in diagrams[0] if float('inf') in x]\n",
    "            \n",
    "    # If there is a 1-dim betti number, it is returned.\n",
    "    if len(diagrams) == 2:\n",
    "        \n",
    "        # Calculates the 1-dim betti number.\n",
    "        betti1 = [1 for x in diagrams[1] if float('inf') in x]\n",
    "        \n",
    "        # Returns the betti numbers.\n",
    "        return (len(betti0),len(betti1))\n",
    "    \n",
    "    # Otherwise b1 = 0.\n",
    "    else:\n",
    "        # Returns the betti numbers.\n",
    "        return(len(betti0),0)\n",
    "\n",
    "    \n",
    "# Function to create classification vectors for data sets.\n",
    "def classificationVector(dataSet, flag):\n",
    "    '''Inputs: -dataSet: The data set to be analyzed.\n",
    "               -flag: Flag to control single vector analysis or whole data set analysis.\n",
    "                       Either 'single' or 'whole'.\n",
    "    \n",
    "       Outputs: -dataVect: A matrix containing vectors of weights corresponding\n",
    "                           to signatures from the data set. (Called dataVect for\n",
    "                           a single vector, or totalDataVect for the whole set.)\n",
    "    '''\n",
    "    \n",
    "    # List with the scanning types to iterate through.\n",
    "    scanTypes = ['ud', 'du', 'lr', 'mo-hori', 'dist1', 'ptdim', 'shortlr','ends', 'width']\n",
    "    \n",
    "    # Creates classification vectors for each character in the data set.\n",
    "    if flag.lower() == 'whole':\n",
    "        \n",
    "        # List holding numpy arrays of each classification vector.\n",
    "        totalDataVect = []\n",
    "    \n",
    "        j = 0    # loop control variable.\n",
    "    \n",
    "        # Iterates through the data set and creates classification vectors\n",
    "        # for each character.\n",
    "        while j != len(dataSet):\n",
    "            \n",
    "            letter_one_line = dataSet[j,:]    # Loads the data for one character from the data set.\n",
    "            dataVect = np.array([])           # Creates an empty array to hold the classification features\n",
    "        \n",
    "            # Finds the total betti numbers for each data set and places it in the positions 0 and 1\n",
    "            # of the vector.\n",
    "            (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 101, eps = 1.42, showPlot = False, doSlice = False)\n",
    "            dataVect = np.append(dataVect,b0)\n",
    "            dataVect = np.append(dataVect,b1)\n",
    "        \n",
    "            # Iterating through the different scan types and adding to dataVect\n",
    "            # features depending on the scan type. Each feature is a number between\n",
    "            # 0 and 1. For betti numbers this is calculated as (100-bn)/100, where\n",
    "            # n = 0 or 1. For width this is calulated as width/100.\n",
    "            for sc in scanTypes:\n",
    "                \n",
    "                # bottom-to-top scanning is done on the bottom half of the character.\n",
    "                if sc.lower() == 'du':\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'ud', 45, 101, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                    dataVect = np.append(dataVect,(100-b1)/100)\n",
    "        \n",
    "                # Horizontal middle-out scanning on the middle third of the character.\n",
    "                elif sc.lower() == 'mo-hori':\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'ud', 25, 76, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                    dataVect = np.append(dataVect,(100-b1)/100)\n",
    "        \n",
    "                # Width scanning. The scan interval is kept at a fixed [50-i, 50+i] and i is increased until\n",
    "                # either b1 is greater than or equal to 1, or the entire character is scanned.\n",
    "                # This width gives the 'time' when the first 1D 'hole' is found. This is calculated as\n",
    "                # the length of the interval which is 50+i - (50-i) = 2*i. It is then reweighted with division\n",
    "                # by 100.\n",
    "                elif sc.lower() == 'width':\n",
    "                    \n",
    "                    scanWidth = 0    # Initializes scanWidth to be zero.\n",
    "                    \n",
    "                    # Increases the width in increments of 10, with i ranging from 1 to 50.\n",
    "                    for i in range(1,50,10):\n",
    "                        \n",
    "                        # The beginning and end of the scan interval.\n",
    "                        scStart = 50-i\n",
    "                        scStop = 50+i\n",
    "                        \n",
    "                        # Calculates the betti numbers for the character at the current width.\n",
    "                        (b0,b1) = betti_nums(letter_one_line, 'lr', scStart, scStop, eps = 1.42, showPlot = False, doSlice = False)\n",
    "\n",
    "                        # If b1 is greater than or equal to 1, the width calculated as 2*i, and the loop is broken.\n",
    "                        if b1 >= 1:\n",
    "                            scanWidth = 2*i\n",
    "                            break\n",
    "                    \n",
    "                    # Appends the width to the classification vector.\n",
    "                    dataVect = np.append(dataVect,scanWidth/100)\n",
    "                    \n",
    "                    scanWidth = 0    # Resets scanWidth back to zero.\n",
    "        \n",
    "                # Up-and-Down scanning, but with the 'infinity' being equal to 1. This connects the skeleton\n",
    "                # of the character, but without filling in the 'holes' that get filled in a distance of ~1.42.\n",
    "                elif sc.lower() == 'dist1':\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 101, eps = 1.0, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                    dataVect = np.append(dataVect,(100-b1)/100)\n",
    "        \n",
    "                # Calculates the number of 'pixels' in the character. This is equivalent to the number of points\n",
    "                # in the point cloud (i.e. the number of 1's in the data for the character).\n",
    "                elif sc.lower() == 'ptdim':\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 101, eps = 0, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                    dataVect = np.append(dataVect,(100-b1)/100)\n",
    "            \n",
    "                # Left-to-Right scanning in a shorter interval than normal. This is done to pick up any 'endpoints'\n",
    "                # of characters that are missed in the normal left-to-right scan.\n",
    "                elif sc.lower() == 'shortlr':\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'lr', 1, 40, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                    dataVect = np.append(dataVect,(100-b1)/100)\n",
    "                    \n",
    "                # Short scanning Up-and-Down, Down-and-Up, and Left-to-Right. Effectively calculating the ends\n",
    "                # of the structure if the middle is excised.\n",
    "                elif sc.lower() == 'ends':\n",
    "                    (b0u,b1u) = betti_nums(letter_one_line,'ud', 1,21, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    (b0d,b1d) = betti_nums(letter_one_line,'ud', 80,101, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    (b0l,b1l) = betti_nums(letter_one_line,'lr', 1,31, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect, (100-(b0u+b0d+b0l))/100)\n",
    "            \n",
    "                \n",
    "                # The remaining scan types (ud and lr) on half of the character.\n",
    "                else:\n",
    "                    (b0,b1) = betti_nums(letter_one_line, sc, 1, 86, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                    dataVect = np.append(dataVect,(100-b1)/100)\n",
    "        \n",
    "            # Adds the classifcation vector for the jth character to the total list of vectors.\n",
    "            totalDataVect.append(dataVect)\n",
    "            \n",
    "            # Increments j.\n",
    "            j += 1\n",
    "        \n",
    "        # Returns the total list of classification vectors.\n",
    "        return totalDataVect\n",
    "    \n",
    "    # Creates a classification vector for one character.\n",
    "    elif flag.lower() == 'single':\n",
    "        \n",
    "        letter_one_line = dataSet    # Loads the data for the one character.\n",
    "        dataVect = np.array([])      # Creates an empty array to hold the classification features\n",
    "        \n",
    "        # Finds the total betti numbers for each data set and places it in the positions 0 and 1\n",
    "        # of the vector.\n",
    "        (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 101, eps = 1.42, showPlot = False, doSlice = False)\n",
    "        dataVect = np.append(dataVect,b0)\n",
    "        dataVect = np.append(dataVect,b1)\n",
    "        \n",
    "        # Iterating through the different scan types and adding to dataVect\n",
    "        # features depending on the scan type. Each feature is a number between\n",
    "        # 0 and 1. For betti numbers this is calculated as (100-bn)/100, where\n",
    "        # n = 0 or 1. For width this is calulated as width/100.\n",
    "        for sc in scanTypes:\n",
    "            \n",
    "            # bottom-to-top scanning is done on the bottom half of the character.\n",
    "            if sc.lower() == 'du':\n",
    "                (b0,b1) = betti_nums(letter_one_line, 'ud', 45, 101, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                dataVect = np.append(dataVect,(100-b1)/100)\n",
    "            \n",
    "            # Horizontal middle-out scanning on the middle third of the character.\n",
    "            elif sc.lower() == 'mo-hori':\n",
    "                (b0,b1) = betti_nums(letter_one_line, 'ud', 25, 76, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                dataVect = np.append(dataVect,(100-b1)/100)\n",
    "            \n",
    "            # Width scanning. The scan interval is kept at a fixed [50-i, 50+i] and i is increased until\n",
    "            # either b1 is greater than or equal to 1, or the entire character is scanned.\n",
    "            # This width gives the 'time' when the first 1D 'hole' is found. This is calculated as\n",
    "            # the width of the interval which is 50+i - (50-i) = 2*i. It is then reweighted with division\n",
    "            # by 100.\n",
    "            elif sc.lower() == 'width':\n",
    "                \n",
    "                scanWidth = 0    # Initializes scanWidth to be zero.\n",
    "                \n",
    "                # Increases the width in increments of 10, with i ranging from 1 to 50.\n",
    "                for i in range(1,50,10):\n",
    "                    \n",
    "                    # The beginning and end of the scan interval.\n",
    "                    scStart = 50-i\n",
    "                    scStop = 50+i\n",
    "                    \n",
    "                    # Calculates the betti numbers for the character at the current width.\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'lr', scStart, scStop, eps = 1.42, showPlot = False, doSlice = False)\n",
    "\n",
    "                    # If b1 is greater than or equal to 1, the width calculated as 2*i, and the loop is broken.\n",
    "                    if b1 >= 1:\n",
    "                        scanWidth = 2*i\n",
    "                        break\n",
    "                \n",
    "                # Appends the width to the classification vector.\n",
    "                dataVect = np.append(dataVect,scanWidth/100)\n",
    "                \n",
    "                scanWidth = 0    # Resets scanWidth back to zero.\n",
    "        \n",
    "            # Up-and-Down scanning, but with the 'infinity' being equal to 1. This connects the skeleton\n",
    "            # of the character, but without filling in the 'holes' that get filled in a distance of ~1.42.\n",
    "            elif sc.lower() == 'dist1':\n",
    "                (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 101, eps = 1.0, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                dataVect = np.append(dataVect,(100-b1)/100)\n",
    "        \n",
    "            # Calculates the number of 'pixels' in the character. This is equivalent to the number of points\n",
    "            # in the point cloud (i.e. the number of 1's in the data for the character).\n",
    "            elif sc.lower() == 'ptdim':\n",
    "                (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 101, eps = 0, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                dataVect = np.append(dataVect,(100-b1)/100)\n",
    "            \n",
    "            # Left-to-Right scanning in a shorter interval than normal. This is done to pick up any 'endpoints'\n",
    "            # of characters that are missed in the normal left-to-right scan.\n",
    "            elif sc.lower() == 'shortlr':\n",
    "                (b0,b1) = betti_nums(letter_one_line, 'lr', 1, 40, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                dataVect = np.append(dataVect,(100-b1)/100)\n",
    "            \n",
    "            # Short scanning Up-and-Down, Down-and-Up, and Left-to-Right. Effectively calculating the ends\n",
    "            # of the structure if the middle is excised.\n",
    "            elif sc.lower() == 'ends':\n",
    "                (b0u,b1u) = betti_nums(letter_one_line,'ud', 1,21, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                (b0d,b1d) = betti_nums(letter_one_line,'ud', 80,101, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                (b0l,b1l) = betti_nums(letter_one_line,'lr', 1,31, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect, (100-(b0u+b0d+b0l))/100)\n",
    "            \n",
    "            # The remaining scan types (ud and lr) on half of the character.\n",
    "            else:\n",
    "                (b0,b1) = betti_nums(letter_one_line, sc, 1, 86, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(100-b0)/100)\n",
    "                dataVect = np.append(dataVect,(100-b1)/100)\n",
    "        \n",
    "        return dataVect    # Returns the single classification vector.\n",
    "    \n",
    "\n",
    "# Function to compare the unknown character to the known characters\n",
    "# and decide which character the uknown is.\n",
    "def comparison(known, unknown):\n",
    "    '''Inputs: -known: A list of weight vectors for the letters.\n",
    "               -unknown: A weight vector for the unknown letter.\n",
    "        \n",
    "       Outputs: -unknownLetter: A string containing the classified\n",
    "                                unknown letter.\n",
    "    '''\n",
    "    distance = 0      # The distance between the classification vectors for the known and unknown characters.\n",
    "    distances = []    # List holding the distances between the unknown vector and the known vectors\n",
    "    \n",
    "    # The outer loop ranges from 0 to the length of the list of the known character classification vectors.\n",
    "    # The inner loop ranges from 0 to the length of the unknown classification vector. Calculates the\n",
    "    # Euclidean distance between the classification vector for the unknown character and the classification\n",
    "    # vectors for the known characters. After each pass of the outer loop, the hth distance is added to the\n",
    "    # distances list.\n",
    "    for h in range(0,len(known)):\n",
    "        for i in range(0,len(unknown)):\n",
    "            distance += (unknown[i]-known[h][i])**2\n",
    "        distances.append(math.sqrt(distance))\n",
    "        distance = 0\n",
    "    \n",
    "    # Alphabet of the 26 latin letters, 5 punctuation marks, and a space.\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz., -:;'\n",
    "    \n",
    "    # Determines the index of the minimum distance in the distances list.\n",
    "    clsif = distances.index(min(distances))\n",
    "    \n",
    "    # Returns the symbol at index clsif of the alphabet string. This is the\n",
    "    # decision on which symbol the unknown symbol is.\n",
    "    return alphabet[clsif].upper()\n",
    "\n",
    "\n",
    "# Function to add noise to the data set, and attempt to classify the noisy data.\n",
    "def noiseTests(noiseType, dSet, dSetVect):\n",
    "    '''Inputs: -noiseType: A string signifying the type of noise to add.\n",
    "                           Either '0', '1', 'rand', or 'none'.\n",
    "                        '0': Randomly changes five data points to zeroes.\n",
    "                        '1': Randomly changes five data points to ones.\n",
    "                        'rand': Randomly changes five data points to 0 or 1.\n",
    "                               This is chosen randomly.\n",
    "                        'none': No noise is added to the data set. This should\n",
    "                               result in a classification rate of 1.\n",
    "                               \n",
    "               -dSet: The data set to be analyzed.\n",
    "               \n",
    "               -dSetVect: A list of classification vectors calculated from the data set.\n",
    "       \n",
    "       Outputs: -classRate: A floating point number between 0 and 1 signifying\n",
    "                            the proportion of correctly classified letters to\n",
    "                            the total number of letters. e.g. if there was 100%\n",
    "                            classification, this number would be 1.\n",
    "    \n",
    "    '''\n",
    "    # Supresses any warning messages.\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Alphabet of letters.\n",
    "    alph = 'abcdefghijklmnopqrstuvwxyz., -:;'\n",
    "    \n",
    "    if noiseType.lower() == 'none':\n",
    "        print('Classification Rate without noise: ')\n",
    "    \n",
    "    correct = 0    # The number of correctly classified letters.\n",
    "\n",
    "    # Iterates over each letter in the data set of letters, adds noise,\n",
    "    # and tries to classify the noisy letter.\n",
    "    for i in range(0,32):\n",
    "    \n",
    "        # Loading letter to add random noise.\n",
    "        unknownLetter = copy.deepcopy(dSet[i,:])\n",
    "        \n",
    "        # Vector of coordinates to change.\n",
    "        noise = random.sample(range(1,100), 5)\n",
    "\n",
    "        if noiseType.lower() == '0':\n",
    "            \n",
    "            # Adds noise to the letter by changing coordinates corresponding to\n",
    "            # the values in the noise vector to 0's.\n",
    "            for k in noise:\n",
    "                unknownLetter[k] = 0\n",
    "        \n",
    "        elif noiseType.lower() == '1':\n",
    "            \n",
    "            # Adds noise to the letter by changing coordinates corresponding to\n",
    "            # the values in the noise vector to 1's.\n",
    "            for k in noise:\n",
    "                unknownLetter[k] = 1\n",
    "                    \n",
    "        elif noiseType.lower() == 'rand':\n",
    "            \n",
    "            # Adds noise to the letter by changing coordinates corresponding to\n",
    "            # the values in the noise vector to 0 or 1, chosen randomly.\n",
    "            for k in noise:\n",
    "                unknownLetter[k] = random.randint(0,1)\n",
    "                \n",
    "        # Calls the ClassificationVector function to generate a classification\n",
    "        # vector for the unknown letter.\n",
    "        unknownVect = classificationVector(unknownLetter, 'single')\n",
    "\n",
    "        # Calls the comparison function to determine the unknown character.\n",
    "        prediction = comparison(dSetVect, unknownVect)\n",
    "    \n",
    "        # If the letter is accurately classified, the number of correct\n",
    "        # classifications is incremented.\n",
    "        if prediction == alph[i].upper():\n",
    "            correct += 1\n",
    "    \n",
    "        # Resets the noise to be empty.\n",
    "        noise = []\n",
    "\n",
    "    # Returns the classification rate of the noisy letters as the proportion of\n",
    "    # correctly classified letters to the total number of letters.\n",
    "    classRate = correct/32\n",
    "    return classRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the classification methods on the data set without added noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Rate without noise: \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Loads the letters data set and calculates the list of classification vectors for\n",
    "# the letters.\n",
    "letterSet = genfromtxt('../AMAT585/letters.csv', delimiter = ',')\n",
    "letterSetVect = classificationVector(letterSet, 'whole')\n",
    "\n",
    "# Calculates the classification rate for the data set without noise.\n",
    "# This should be result in 100% classification.\n",
    "print(noiseTests('none',letterSet, letterSetVect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the classification methods on the data set with added noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average classification rate for 0-type noise added to the data set is: \n",
      "0.59125\n",
      "\n",
      "The average classification rate for 1-type noise added to the data set is: \n",
      "0.1775\n",
      "\n",
      "The average classification rate for random-type noise added to the data set is: \n",
      "0.291875\n"
     ]
    }
   ],
   "source": [
    "# Performing 100 tests of classifying the data set of letters with noise added.\n",
    "# Then, the average classification rate is calculated. This is performed three\n",
    "# times, once for each type of noise.\n",
    "\n",
    "# Loads the letters data set and calculates the list of classification vectors for\n",
    "# the letters.\n",
    "letterSet = genfromtxt('../AMAT585/letters.csv', delimiter = ',')\n",
    "letterSetVect = classificationVector(letterSet, 'whole')\n",
    "\n",
    "classifVect0 = []       # Vector classification rates for added 0's noise.\n",
    "classifVect1 = []       # Vector classification rates for added 1's noise.\n",
    "classifVectRand = []    # Vector classification rates for randomly added 0's of 1's noise.\n",
    "\n",
    "# Calls the noiseTest function 100 times to collect a large sample size\n",
    "# of classification rates for each noise type.\n",
    "for h in range(1,101):\n",
    "    classifVect0.append(noiseTests('0', letterSet, letterSetVect))\n",
    "    classifVect1.append(noiseTests('1',letterSet, letterSetVect))\n",
    "    classifVectRand.append(noiseTests('rand',letterSet, letterSetVect))\n",
    "\n",
    "# Displays the average classification rates for each noise type.\n",
    "print('The average classification rate for 0-type noise added to the data set is: ')\n",
    "print(sum(classifVect0)/100)\n",
    "print()\n",
    "\n",
    "print('The average classification rate for 1-type noise added to the data set is: ')\n",
    "print(sum(classifVect1)/100)\n",
    "print()\n",
    "\n",
    "print('The average classification rate for random-type noise added to the data set is: ')\n",
    "print(sum(classifVectRand)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
